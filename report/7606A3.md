# 7606Assignment3 Reasoning on ARC dataset with Large Language Models

## Overview

The main purpose of this article is to examine how several hyperparamters will influence the performance of the Large Language Models(LLM) Inference. In particular, we use Llama-3.2 models as the test model, and the ARC dataset, a multiple-choice question answering dataset, as the 

### LLM



### ARC dataset

1172 Questions(challenge test set)

The ARC dataset consists of 7787 science questions, all non-diagram, multiple choice (typically 4-way multiple choice). They are drawn from a variety of sources, and sorted into a Challenge Set of 2590 “hard” questions (those that both a retrieval and a co-occurrence method fail to answer correctly) and an Easy Set of 5197 questions. Each set are further divided into train/dev/test set.

In this experiment, all reasoning test is based on the test partition of the challenge set, with 1172 questions at all.

### Related Works

GPT4 (96.4%ACC)(do not find in the thesis)

## Method

## Experiment

### Analysis

(Specific Hyperparameter Analysis and Performance Metrics)

temperature (0.2, 0.4, 0.6, 0.8, 1.0)
(default=0.6)
because in the llama thesis, the authors try 0.2~1.0, and finally choose a constant value of 0.6 to balance the trade-off.(which is same to the outcome of different tempature in our experiments.)

number of forward pass (4, 8, 16)
(default=8)

model selection (Llama-3.2-1B-Instruct, Llama-3.2-3B-Instruct)
(default=Llama-3.2-1B-Instruct)

### Reasoning behind hyperparameter choice and algorithm decisions

Maybe a plot of confidence <-> accuracy?

### Metrics

Accuracy in the challenge test set of ARC dataset.

## Others

### meaning of Instruct in model name

chenqiang@connect.hku.hk [08/11/2024, 16:57:02]:
What's the difference between the model "Llama-3.2-3B-Instruct" and "Llama-3.2-3B"? What does the instruct mean?
————————————————————————————————————
GPT-4o [08/11/2024, 16:57:02]:
The model names "Llama-3.2-3B-Instruct" and "Llama-3.2-3B" suggest that they are versions of the Llama model with different training objectives or usage scenarios.

1. Llama-3.2-3B: This is a general-purpose language model with 3 billion parameters. It is designed to perform a wide variety of natural language processing tasks based on the data it has been trained on.

2. Llama-3.2-3B-Instruct: The "Instruct" in the model name indicates that this version of the model has been fine-tuned specifically for instruction-following tasks. This means that it has been trained using datasets that focus on following user instructions, making it more effective and reliable for tasks where the model needs to understand and respond accurately to specific queries or commands.

In summary, the "Instruct" variant is optimized for scenarios where the model needs to follow instructions closely, providing more accurate and contextually appropriate responses to user inputs.

### temperature
chenqiang@connect.hku.hk [08/11/2024, 17:35:17]:
What does the hyper-parameter "temperature" mean in large language models? Where does it comes from?
————————————————————————————————————
GPT-4o [08/11/2024, 17:35:17]:
In the context of large language models, the hyper-parameter "temperature" is used to control the randomness of the model's predictions during text generation. It is a parameter that can be adjusted to influence the diversity and creativity of the generated text.

Here's a detailed explanation:

What is Temperature?
Temperature is a parameter that scales the logits (raw prediction scores) before they are transformed into probabilities via the softmax function.
When generating text, the model computes a probability distribution over the possible next tokens (words or characters). The temperature parameter adjusts this distribution.
How Does Temperature Work?
Low Temperature (< 1): When the temperature is set to a value less than 1, the model's predictions become more deterministic and focused. The probability distribution becomes sharper, meaning the model is more likely to choose the highest-probability token. This results in more predictable and conservative text generation.
High Temperature (> 1): When the temperature is set to a value greater than 1, the model's predictions become more random and diverse. The probability distribution becomes flatter, meaning the model is more likely to choose lower-probability tokens. This results in more varied and creative text generation.
Temperature = 1: When the temperature is set to 1, the model's predictions are not scaled, and the distribution remains as originally computed.
Mathematical Formulation
Let ( \mathbf{z} ) be the logits vector (raw scores) for the next token. The softmax function with temperature ( T ) is applied as follows: [ \text{softmax}(\mathbf{z}/T) ]

When ( T ) is low, ( \mathbf{z}/T ) increases the differences between logits, making the softmax output more peaked (less random).
When ( T ) is high, ( \mathbf{z}/T ) decreases the differences between logits, making the softmax output more uniform (more random).
Origin of Temperature
The concept of temperature in this context is borrowed from statistical mechanics, where temperature controls the randomness in the distribution of particle states.
In language models, it serves a similar purpose by controlling the randomness in the choice of the next token during generation.
Practical Use
Adjusting the temperature allows users to control the trade-off between diversity and coherence in the generated text.
Lower temperatures are useful when a more focused and coherent response is desired.
Higher temperatures can be useful when exploring more creative or less predictable text outputs.
In summary, the temperature parameter is a crucial tool for managing the balance between determinism and creativity in text generation with large language models.

### temperature in llama thesis

Generation: We explored randomly choosing the temperature hyperparameter from the range 0.2 − 1 for diverse generations in early rounds of post-training. With high temperature, responses for multilingual prompts can get creative and inspiring, but are also susceptible to unnecessary or unnatural code-switching. In the final round of post-training, we use a constant value of 0.6 to balance the trade-off. Additionally, we used specialized system prompts to improve response format, structure and general readability.